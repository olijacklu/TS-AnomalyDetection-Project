{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to obtain scores (plain vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code only serves as a tutorial of how to set up and run the different algorithms. No need to run it if the performance_evaluation, gridsearch and ensemble notebooks work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from docker) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->docker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->docker) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->docker) (2024.12.14)\n",
      "\u001b[33mWARNING: Error parsing dependencies of timeeval: .* suffix can only be used with `==` or `!=` operators\n",
      "    scikit-learn (>=0.24.*)\n",
      "                  ~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: timeeval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.2.6)\n",
      "Requirement already satisfied: durations in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpyencoder in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: distributed in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2024.12.1)\n",
      "Requirement already satisfied: prts in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.0.3)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numpyencoder) (1.26.4)\n",
      "Requirement already satisfied: click>=8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: dask==2024.12.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2024.12.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.1.4)\n",
      "Requirement already satisfied: locket>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (24.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (6.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (6.0.2)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: toolz>=0.11.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (6.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2.2.2)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask==2024.12.1->distributed) (2024.9.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask==2024.12.1->distributed) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.10.3->distributed) (2.1.5)\n",
      "\u001b[33mWARNING: Error parsing dependencies of timeeval: .* suffix can only be used with `==` or `!=` operators\n",
      "    scikit-learn (>=0.24.*)\n",
      "                  ~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install docker\n",
    "!pip install timeeval --no-deps\n",
    "!pip install durations numpyencoder distributed prts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from timeeval.utils.window import ReverseWindowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Docker is installed and running (if not install it from here: https://docs.docker.com/engine/install/ and open the app to allow Docker to run in the background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_docker():\n",
    "    if not shutil.which(\"docker\"):\n",
    "        raise EnvironmentError(\"Docker is not installed or not in your PATH. Please install Docker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_docker_images():\n",
    "    images = [\n",
    "        \"ghcr.io/timeeval/cblof:0.3.0\"\n",
    "    ]\n",
    "\n",
    "    # Build Docker images\n",
    "    for image in images:\n",
    "        try:\n",
    "            subprocess.run([\"docker\", \"pull\", \"--platform\", \"linux/amd64\", image], check=True)\n",
    "            print(f\"Successfully pulled {image}.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to pull {image}: {e}\")\n",
    "\n",
    "\n",
    "pull_docker_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the algorithms you wish to run with there respective Docker images (can be found at https://github.com/TimeEval/TimeEval-algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS = {\"CBLOF\": \"ghcr.io/timeeval/cblof:0.3.0\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function allowing you to run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(algorithm_name, data_path, execution_type=\"execute\", custom_parameters=None):\n",
    "\n",
    "    # Check if Docker image of algorithm was specified\n",
    "    if algorithm_name not in ALGORITHMS:\n",
    "        raise ValueError(f\"Algorithm '{algorithm_name}' not found in ALGORITHMS dictionary.\")\n",
    "\n",
    "    # Construct configuration\n",
    "    config = {\n",
    "        \"executionType\": execution_type,\n",
    "        \"dataInput\": f\"/data/{data_path}\",\n",
    "        \"dataOutput\": \"/results/anomaly_scores.csv\",\n",
    "        \"modelInput\": \"/results/model.pkl\" if execution_type == \"train\" else \"/results/trained_model.pkl\",\n",
    "        \"modelOutput\": \"/results/trained_model.pkl\" if execution_type == \"train\" else \"/results/model.pkl\",\n",
    "        \"customParameters\": custom_parameters or {}\n",
    "    }\n",
    "    \n",
    "    config_json = json.dumps(config)\n",
    "\n",
    "    # Build Docker command\n",
    "    cmd = [\n",
    "        \"docker\", \"run\", \"--rm\",\n",
    "        \"-v\", f\"{os.getcwd()}/data:/data:ro\",\n",
    "        \"-v\", f\"{os.getcwd()}/results:/results:rw\",\n",
    "        \"--platform\", \"linux/amd64\",  # Ensures compatibility on ARM machines (might need to be adjusted depending on the architecture)!\n",
    "        ALGORITHMS[algorithm_name],\n",
    "        \"execute-algorithm\",\n",
    "        config_json\n",
    "    ]\n",
    "\n",
    "    # Execute Docker command\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running {algorithm_name}: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Execution failed for {algorithm_name}\")\n",
    "\n",
    "    # Load and return anomaly scores\n",
    "    scores_path = \"./results/anomaly_scores.csv\"\n",
    "    scores = np.loadtxt(scores_path, delimiter=\",\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that evaluates the algorithm based on the produced anomaly scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(scores, data_path):\n",
    "    # Load test data\n",
    "    data_test = pd.read_csv(data_path)\n",
    "    \n",
    "    # Ensure 'is_anomaly' column exists in the data\n",
    "    if 'is_anomaly' not in data_test.columns:\n",
    "        raise ValueError(f\"The test data at {data_path} must contain an 'is_anomaly' column.\")\n",
    "\n",
    "    # Extract the anomaly labels\n",
    "    anomalies = data_test['is_anomaly']\n",
    "\n",
    "    # Calculate AUC-ROC and AUC-PR\n",
    "    auc_roc = roc_auc_score(anomalies, scores)\n",
    "    precision, recall, _ = precision_recall_curve(anomalies, scores)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    return auc_roc, auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing for STAMP\n",
    "def post_stamp(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_size = args.get(\"hyper_params\", {}).get(\"anomaly_window_size\", 30)\n",
    "    if window_size < 4:\n",
    "      print(\"WARN: window_size must be at least 4. Dynamically fixing it by setting window_size to 4\")\n",
    "      window_size = 4\n",
    "    return ReverseWindowing(window_size=window_size).fit_transform(scores)\n",
    "\n",
    "# Post-processing for STOMP\n",
    "def post_stomp(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_size = args.get(\"hyper_params\", {}).get(\"anomaly_window_size\", 30)\n",
    "    if window_size < 4:\n",
    "      print(\"WARN: window_size must be at least 4. Dynamically fixing it by setting window_size to 4\")\n",
    "      window_size = 4\n",
    "    return ReverseWindowing(window_size=window_size).fit_transform(scores)\n",
    "\n",
    "# Post-processing for Sub-LOF\n",
    "def post_sLOF(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_size = args.get(\"hyper_params\", {}).get(\"window_size\", 100)\n",
    "    return ReverseWindowing(window_size=window_size).fit_transform(scores)\n",
    "\n",
    "# Post-processing for VALMOD\n",
    "def post_valmod(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_min = args.get(\"hyper_params\", {}).get(\"min_anomaly_window_size\", 30)\n",
    "    window_min = max(window_min, 4)\n",
    "    return ReverseWindowing(window_size=window_min).fit_transform(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example run for CBLOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly scores: [0.72792853 0.68567176 0.78575383 ... 1.01723518 1.22767215 1.0791532 ]\n"
     ]
    }
   ],
   "source": [
    "# Run CBLOF on an example dataset\n",
    "try:\n",
    "    anomaly_scores = run_algorithm(\n",
    "        algorithm_name=\"CBLOF\",\n",
    "        data_path=\"GutenTAG/cbf-trend-quadratic/test.csv\",\n",
    "        execution_type=\"execute\",\n",
    "        custom_parameters={\n",
    "            \"n_clusters\": 50,\n",
    "            \"alpha\": 0.9,\n",
    "            \"beta\": 5,\n",
    "            \"use_weights\": False\n",
    "        }\n",
    "    )\n",
    "    print(\"Anomaly scores:\", anomaly_scores)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
