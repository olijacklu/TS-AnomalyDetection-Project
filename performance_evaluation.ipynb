{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation (with plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows you to run different algorithms on a certain set of datasets, obtain their AUC-ROC and AUC-PR scores and obtain the associated plot highlighting the anomaly scores, as well as the original anomalous time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timeeval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.2.6)\n",
      "Requirement already satisfied: durations in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpyencoder in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: distributed in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2024.12.1)\n",
      "Requirement already satisfied: prts in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.0.3)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numpyencoder) (1.26.4)\n",
      "Requirement already satisfied: click>=8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: dask==2024.12.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2024.12.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.1.4)\n",
      "Requirement already satisfied: locket>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (24.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (6.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (6.0.2)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: toolz>=0.11.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/oliverjack/Library/Python/3.12/lib/python/site-packages (from distributed) (6.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (2.2.2)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask==2024.12.1->distributed) (2024.9.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask==2024.12.1->distributed) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.10.3->distributed) (2.1.5)\n",
      "\u001b[33mWARNING: Error parsing dependencies of timeeval: .* suffix can only be used with `==` or `!=` operators\n",
      "    scikit-learn (>=0.24.*)\n",
      "                  ~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install docker\n",
    "!pip install timeeval --no-deps\n",
    "!pip install durations numpyencoder distributed prts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from timeeval.utils.window import ReverseWindowing\n",
    "import signal\n",
    "import threading\n",
    "import time\n",
    "from functools import wraps\n",
    "import platform\n",
    "import psutil\n",
    "import gc\n",
    "import traceback\n",
    "from typing import Optional\n",
    "from concurrent.futures import TimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Docker is installed and running (if not install it from here: https://docs.docker.com/engine/install/ and open the app to allow Docker to run in the background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_docker():\n",
    "    if not shutil.which(\"docker\"):\n",
    "        raise EnvironmentError(\"Docker is not installed or not in your PATH. Please install Docker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.0: Pulling from timeeval/cblof\n",
      "Digest: sha256:4397c29daaac6a99d8cfc572fec055bf81a6bcad43cadc503c85443cd422f9be\n",
      "Status: Image is up to date for ghcr.io/timeeval/cblof:0.3.0\n",
      "ghcr.io/timeeval/cblof:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/cblof:0.3.0.\n",
      "0.3.0: Pulling from timeeval/cof\n",
      "Digest: sha256:b6d9200d41641cf443bed91f3498b3b26f36b84d8fcb533f561c1279a7806352\n",
      "Status: Image is up to date for ghcr.io/timeeval/cof:0.3.0\n",
      "ghcr.io/timeeval/cof:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/cof:0.3.0.\n",
      "0.3.0: Pulling from timeeval/kmeans\n",
      "Digest: sha256:acd5f5f6c8a644a02fa755e0fc274d323263f2f34e43e496fc174224b03e0ec8\n",
      "Status: Image is up to date for ghcr.io/timeeval/kmeans:0.3.0\n",
      "ghcr.io/timeeval/kmeans:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/kmeans:0.3.0.\n",
      "0.3.0: Pulling from timeeval/knn\n",
      "Digest: sha256:a9bb4f68b291c0f91654c1275da9089e91ddff2203ecfbbc504af12504f461be\n",
      "Status: Image is up to date for ghcr.io/timeeval/knn:0.3.0\n",
      "ghcr.io/timeeval/knn:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/knn:0.3.0.\n",
      "0.3.0: Pulling from timeeval/lof\n",
      "Digest: sha256:062c171717ca8dbbd4af805aaa0cef0897f9c6b934fbecaf96f3b6978a7f4436\n",
      "Status: Image is up to date for ghcr.io/timeeval/lof:0.3.0\n",
      "ghcr.io/timeeval/lof:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/lof:0.3.0.\n",
      "0.3.0: Pulling from timeeval/phasespace_svm\n",
      "Digest: sha256:c886a6aa1de60f5821bcc10818e4601ca3896552637827174db3fd887a5382f4\n",
      "Status: Image is up to date for ghcr.io/timeeval/phasespace_svm:0.3.0\n",
      "ghcr.io/timeeval/phasespace_svm:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/phasespace_svm:0.3.0.\n",
      "0.3.0: Pulling from timeeval/stamp\n",
      "Digest: sha256:8a7e9ffdbec4b07aef587e10e650e57a409ccdc8aa74131e4393380f93acd62f\n",
      "Status: Image is up to date for ghcr.io/timeeval/stamp:0.3.0\n",
      "ghcr.io/timeeval/stamp:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/stamp:0.3.0.\n",
      "0.3.0: Pulling from timeeval/stomp\n",
      "Digest: sha256:576aa654e9fd2bf312ad89fac8a2be1704a54ddb9ad47b99e1a1008bc2b18c48\n",
      "Status: Image is up to date for ghcr.io/timeeval/stomp:0.3.0\n",
      "ghcr.io/timeeval/stomp:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/stomp:0.3.0.\n",
      "0.3.0: Pulling from timeeval/subsequence_lof\n",
      "Digest: sha256:ef9bdd17f6c507d8a4b2906b6aa8e901a0d6513b3acdee1d1b094063e71fd0d9\n",
      "Status: Image is up to date for ghcr.io/timeeval/subsequence_lof:0.3.0\n",
      "ghcr.io/timeeval/subsequence_lof:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/subsequence_lof:0.3.0.\n",
      "0.3.0: Pulling from timeeval/valmod\n",
      "Digest: sha256:eb49f9d896bdde6bece0b1cc173fac1efefd117158bfacd0efa42d004dff3732\n",
      "Status: Image is up to date for ghcr.io/timeeval/valmod:0.3.0\n",
      "ghcr.io/timeeval/valmod:0.3.0\n",
      "Successfully pulled ghcr.io/timeeval/valmod:0.3.0.\n"
     ]
    }
   ],
   "source": [
    "def pull_docker_images():\n",
    "    images = [\n",
    "        \"ghcr.io/timeeval/cblof:0.3.0\",\n",
    "        \"ghcr.io/timeeval/cof:0.3.0\",\n",
    "        \"ghcr.io/timeeval/kmeans:0.3.0\",\n",
    "        \"ghcr.io/timeeval/knn:0.3.0\",\n",
    "        \"ghcr.io/timeeval/lof:0.3.0\",\n",
    "        \"ghcr.io/timeeval/phasespace_svm:0.3.0\",\n",
    "        \"ghcr.io/timeeval/subsequence_lof:0.3.0\",\n",
    "        \"ghcr.io/timeeval/valmod:0.3.0\"\n",
    "    ]\n",
    "\n",
    "    # Build Docker images\n",
    "    for image in images:\n",
    "        try:\n",
    "            subprocess.run([\"docker\", \"pull\", \"--platform\", \"linux/amd64\", image], check=True)\n",
    "            print(f\"Successfully pulled {image}.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to pull {image}: {e}\")\n",
    "\n",
    "\n",
    "pull_docker_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the algorithms\n",
    "ALGORITHMS = {\n",
    "    \"CBLOF\": \"ghcr.io/timeeval/cblof:0.3.0\",\n",
    "    \"COF\": \"ghcr.io/timeeval/cof:0.3.0\",\n",
    "    \"kMeans\": \"ghcr.io/timeeval/kmeans:0.3.0\",\n",
    "    \"KNN\": \"ghcr.io/timeeval/knn:0.3.0\",\n",
    "    \"LOF\": \"ghcr.io/timeeval/lof:0.3.0\",\n",
    "    \"PS-SVM\": \"ghcr.io/timeeval/phasespace_svm:0.3.0\",\n",
    "    \"Sub-LOF\": \"ghcr.io/timeeval/subsequence_lof:0.3.0\",\n",
    "    \"VALMOD\": \"ghcr.io/timeeval/valmod:0.3.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function allowing you to run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(algorithm_name, data_path, execution_type=\"execute\", custom_parameters=None):\n",
    "\n",
    "    # Check if Docker image of algorithm was specified\n",
    "    if algorithm_name not in ALGORITHMS:\n",
    "        raise ValueError(f\"Algorithm '{algorithm_name}' not found in ALGORITHMS dictionary.\")\n",
    "    \n",
    "    # Check if the data file exists\n",
    "    config = {\n",
    "        \"executionType\": execution_type,\n",
    "        \"dataInput\": \"/\" + data_path,\n",
    "        \"dataOutput\": \"/results/anomaly_scores.csv\",\n",
    "        \"modelInput\": \"/results/model.pkl\" if execution_type == \"train\" else \"/results/trained_model.pkl\",\n",
    "        \"modelOutput\": \"/results/trained_model.pkl\" if execution_type == \"train\" else \"/results/model.pkl\",\n",
    "        \"customParameters\": custom_parameters or {}\n",
    "    }\n",
    "    \n",
    "    config_json = json.dumps(config)\n",
    "    \n",
    "    # Build Docker command\n",
    "    cmd = [\n",
    "        \"docker\", \"run\", \"--rm\",\n",
    "        \"-v\", f\"{os.getcwd()}/data:/data:ro\",\n",
    "        \"-v\", f\"{os.getcwd()}/results:/results:rw\",\n",
    "        \"--platform\", \"linux/amd64\",\n",
    "        ALGORITHMS[algorithm_name], \"execute-algorithm\", config_json\n",
    "    ]\n",
    "    \n",
    "    # Execute Docker command\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running {algorithm_name}: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Execution failed for {algorithm_name}\")\n",
    "    \n",
    "    # Load and return anomaly scores\n",
    "    scores_path = \"./results/anomaly_scores.csv\"\n",
    "    scores = np.loadtxt(scores_path, delimiter=\",\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This class + function handle timeout errors, we have introduced this due to some running for over 60s for a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(timeout):\n",
    "    \"\"\"Decorator that implements timeout for functions on both Unix and Windows\"\"\"\n",
    "    def decorator(func):\n",
    "        if platform.system() != 'Windows':\n",
    "            # Unix-based systems can use signal\n",
    "            def handler(signum, frame):\n",
    "                raise TimeoutError(f\"Function '{func.__name__}' timed out after {timeout} seconds\")\n",
    "\n",
    "            @wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Set signal handler\n",
    "                old_handler = signal.signal(signal.SIGALRM, handler)\n",
    "                signal.alarm(timeout)\n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                finally:\n",
    "                    # Restore old handler and disable alarm\n",
    "                    signal.alarm(0)\n",
    "                    signal.signal(signal.SIGALRM, old_handler)\n",
    "                return result\n",
    "            \n",
    "        else:\n",
    "            # Windows implementation using threading\n",
    "            @wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                result = []\n",
    "                error = []\n",
    "                \n",
    "                def worker():\n",
    "                    try:\n",
    "                        result.append(func(*args, **kwargs))\n",
    "                    except Exception as e:\n",
    "                        error.append(e)\n",
    "                \n",
    "                thread = threading.Thread(target=worker)\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "                thread.join(timeout)\n",
    "                \n",
    "                if thread.is_alive():\n",
    "                    raise TimeoutError(f\"Function '{func.__name__}' timed out after {timeout} seconds\")\n",
    "                if error:\n",
    "                    raise error[0]\n",
    "                return result[0]\n",
    "                \n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same idea as previous block, only for memory related issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryError(Exception):\n",
    "    pass\n",
    "\n",
    "def check_memory_usage(threshold_percent: float = 95.0) -> None:\n",
    "    \"\"\"Check if memory usage is above threshold\"\"\"\n",
    "    memory_percent = psutil.Process(os.getpid()).memory_percent()\n",
    "    if memory_percent > threshold_percent:\n",
    "        raise MemoryError(f\"Memory usage too high: {memory_percent:.1f}%\")\n",
    "\n",
    "def safe_load_data(file_path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Safely load data with error handling\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that evaluates the algorithm based on the produced anomaly scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(scores, data_path):\n",
    "    # Load test data\n",
    "    data_test = pd.read_csv(data_path)\n",
    "    \n",
    "    # Ensure 'is_anomaly' column exists in the data\n",
    "    if 'is_anomaly' not in data_test.columns:\n",
    "        raise ValueError(f\"The test data at {data_path} must contain an 'is_anomaly' column.\")\n",
    "\n",
    "    # Extract the anomaly labels\n",
    "    anomalies = data_test['is_anomaly']\n",
    "\n",
    "    # Calculate AUC-ROC and AUC-PR\n",
    "    auc_roc = roc_auc_score(anomalies, scores)\n",
    "    precision, recall, _ = precision_recall_curve(anomalies, scores)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    return auc_roc, auc_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some algorithms require post-processing. To find out the exact details of which ones need this, head to https://github.com/TimeEval/TimeEval-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing for Sub-LOF\n",
    "def post_sLOF(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_size = args.get(\"hyper_params\", {}).get(\"window_size\", 100)\n",
    "    return ReverseWindowing(window_size=window_size).fit_transform(scores)\n",
    "\n",
    "# Post-processing for VALMOD\n",
    "def post_valmod(scores: np.ndarray, args: dict) -> np.ndarray:\n",
    "    window_min = args.get(\"hyper_params\", {}).get(\"min_anomaly_window_size\", 30)\n",
    "    window_min = max(window_min, 4)\n",
    "    return ReverseWindowing(window_size=window_min).fit_transform(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for entire GutenTAG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/generated_data/dataset_7.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.535, AUC-PR: 0.026\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.401, AUC-PR: 0.020\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.588, AUC-PR: 0.033\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.460, AUC-PR: 0.025\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.420, AUC-PR: 0.020\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.561, AUC-PR: 0.033\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "Error in evaluation phase for STAMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running STOMP for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluation phase for STOMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running Sub-LOF for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-LOF - AUC-ROC: 0.630, AUC-PR: 0.047\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "Error running VALMOD: Welcome to Matrix Profile\n",
      "\n",
      "Attaching package: ‘tsmp’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    write\n",
      "\n",
      "Reading data from /data/generated_data/dataset_7.test.csv\n",
      "Error in if (motifs_per_size > 0) { : \n",
      "  missing value where TRUE/FALSE needed\n",
      "Calls: valmod\n",
      "Execution halted\n",
      "\n",
      "Unexpected error running VALMOD for generated_data: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 101, in <module>\n",
      "    scores = run_algorithm(algo_name, test_file, custom_parameters=custom_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/1694792707.py\", line 26, in run_algorithm\n",
      "    raise RuntimeError(f\"Execution failed for {algorithm_name}\")\n",
      "RuntimeError: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/generated_data/dataset_16.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.538, AUC-PR: 0.074\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.580, AUC-PR: 0.050\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.785, AUC-PR: 0.301\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.566, AUC-PR: 0.065\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.597, AUC-PR: 0.054\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.768, AUC-PR: 0.101\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.584, AUC-PR: 0.052\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.584, AUC-PR: 0.052\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.769, AUC-PR: 0.308\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.584, AUC-PR: 0.052\n",
      "\n",
      "Processing file: data/generated_data/dataset_6.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.518, AUC-PR: 0.013\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.533, AUC-PR: 0.013\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.802, AUC-PR: 0.028\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.563, AUC-PR: 0.019\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.455, AUC-PR: 0.011\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.791, AUC-PR: 0.039\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.583, AUC-PR: 0.065\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.583, AUC-PR: 0.065\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.705, AUC-PR: 0.019\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.583, AUC-PR: 0.065\n",
      "\n",
      "Processing file: data/generated_data/dataset_17.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.602, AUC-PR: 0.200\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.605, AUC-PR: 0.104\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 1.000, AUC-PR: 0.967\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.581, AUC-PR: 0.206\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.661, AUC-PR: 0.038\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.974, AUC-PR: 0.609\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.333, AUC-PR: 0.005\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.333, AUC-PR: 0.005\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 1.000, AUC-PR: 1.000\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.333, AUC-PR: 0.005\n",
      "\n",
      "Processing file: data/generated_data/dataset_0.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.486, AUC-PR: 0.028\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.425, AUC-PR: 0.027\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.375, AUC-PR: 0.024\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.386, AUC-PR: 0.023\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.462, AUC-PR: 0.029\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.628, AUC-PR: 0.042\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "Error in evaluation phase for STAMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running STOMP for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluation phase for STOMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running Sub-LOF for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-LOF - AUC-ROC: 0.441, AUC-PR: 0.041\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "Error running VALMOD: Welcome to Matrix Profile\n",
      "\n",
      "Attaching package: ‘tsmp’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    write\n",
      "\n",
      "Reading data from /data/generated_data/dataset_0.test.csv\n",
      "Error in if (motifs_per_size > 0) { : \n",
      "  missing value where TRUE/FALSE needed\n",
      "Calls: valmod\n",
      "Execution halted\n",
      "\n",
      "Unexpected error running VALMOD for generated_data: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 101, in <module>\n",
      "    scores = run_algorithm(algo_name, test_file, custom_parameters=custom_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/1694792707.py\", line 26, in run_algorithm\n",
      "    raise RuntimeError(f\"Execution failed for {algorithm_name}\")\n",
      "RuntimeError: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/generated_data/dataset_11.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.591, AUC-PR: 0.021\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.614, AUC-PR: 0.032\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.804, AUC-PR: 0.063\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.594, AUC-PR: 0.023\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.578, AUC-PR: 0.021\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.765, AUC-PR: 0.038\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.781, AUC-PR: 0.030\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.781, AUC-PR: 0.030\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.831, AUC-PR: 0.077\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.781, AUC-PR: 0.030\n",
      "\n",
      "Processing file: data/generated_data/dataset_1.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.508, AUC-PR: 0.079\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.536, AUC-PR: 0.055\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.929, AUC-PR: 0.554\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.572, AUC-PR: 0.084\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.563, AUC-PR: 0.034\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.727, AUC-PR: 0.220\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.681, AUC-PR: 0.118\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.681, AUC-PR: 0.118\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.957, AUC-PR: 0.588\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.681, AUC-PR: 0.118\n",
      "\n",
      "Processing file: data/generated_data/dataset_10.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.610, AUC-PR: 0.004\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.699, AUC-PR: 0.006\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.481, AUC-PR: 0.003\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.685, AUC-PR: 0.005\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.539, AUC-PR: 0.005\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.744, AUC-PR: 0.006\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.924, AUC-PR: 0.020\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.924, AUC-PR: 0.020\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.857, AUC-PR: 0.010\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.924, AUC-PR: 0.020\n",
      "\n",
      "Processing file: data/generated_data/dataset_4.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.496, AUC-PR: 0.004\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.558, AUC-PR: 0.007\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.879, AUC-PR: 0.016\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.532, AUC-PR: 0.005\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.617, AUC-PR: 0.007\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.832, AUC-PR: 0.011\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.833, AUC-PR: 0.022\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.833, AUC-PR: 0.022\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.905, AUC-PR: 0.020\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.833, AUC-PR: 0.022\n",
      "\n",
      "Processing file: data/generated_data/dataset_15.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.523, AUC-PR: 0.010\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.183, AUC-PR: 0.005\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.597, AUC-PR: 0.011\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.183, AUC-PR: 0.005\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.437, AUC-PR: 0.006\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.953, AUC-PR: 0.362\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "Error in evaluation phase for STAMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running STOMP for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluation phase for STOMP: Input contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "Running Sub-LOF for generated_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 159, in <module>\n",
      "    auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/2679600840.py\", line 13, in evaluate_algorithm\n",
      "    auc_roc = roc_auc_score(anomalies, scores)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_ranking.py\", line 619, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-LOF - AUC-ROC: 0.000, AUC-PR: 0.005\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "Error running VALMOD: Welcome to Matrix Profile\n",
      "\n",
      "Attaching package: ‘tsmp’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    write\n",
      "\n",
      "Reading data from /data/generated_data/dataset_15.test.csv\n",
      "Error in if (motifs_per_size > 0) { : \n",
      "  missing value where TRUE/FALSE needed\n",
      "Calls: valmod\n",
      "Execution halted\n",
      "\n",
      "Unexpected error running VALMOD for generated_data: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/281630419.py\", line 101, in <module>\n",
      "    scores = run_algorithm(algo_name, test_file, custom_parameters=custom_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/xh/bm_l2jz916s7t2p3pwrcr9y80000gn/T/ipykernel_25469/1694792707.py\", line 26, in run_algorithm\n",
      "    raise RuntimeError(f\"Execution failed for {algorithm_name}\")\n",
      "RuntimeError: Execution failed for VALMOD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/generated_data/dataset_5.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.620, AUC-PR: 0.035\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.624, AUC-PR: 0.034\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.722, AUC-PR: 0.040\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.602, AUC-PR: 0.028\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.564, AUC-PR: 0.027\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.504, AUC-PR: 0.020\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.881, AUC-PR: 0.177\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.881, AUC-PR: 0.177\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.765, AUC-PR: 0.056\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.881, AUC-PR: 0.177\n",
      "\n",
      "Processing file: data/generated_data/dataset_14.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.645, AUC-PR: 0.004\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.627, AUC-PR: 0.004\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.894, AUC-PR: 0.007\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.696, AUC-PR: 0.007\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.661, AUC-PR: 0.003\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.356, AUC-PR: 0.001\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.979, AUC-PR: 0.032\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.979, AUC-PR: 0.032\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.965, AUC-PR: 0.020\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.979, AUC-PR: 0.032\n",
      "\n",
      "Processing file: data/generated_data/dataset_3.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.662, AUC-PR: 0.188\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.671, AUC-PR: 0.058\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.999, AUC-PR: 0.930\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.654, AUC-PR: 0.174\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.582, AUC-PR: 0.025\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.868, AUC-PR: 0.175\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.760, AUC-PR: 0.014\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.760, AUC-PR: 0.014\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 1.000, AUC-PR: 0.962\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.760, AUC-PR: 0.014\n",
      "\n",
      "Processing file: data/generated_data/dataset_12.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.598, AUC-PR: 0.007\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.183, AUC-PR: 0.003\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.931, AUC-PR: 0.035\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.183, AUC-PR: 0.003\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.447, AUC-PR: 0.004\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.952, AUC-PR: 0.184\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.419, AUC-PR: 0.005\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.419, AUC-PR: 0.005\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.390, AUC-PR: 0.004\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.017, AUC-PR: 0.003\n",
      "\n",
      "Processing file: data/generated_data/dataset_2.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.593, AUC-PR: 0.225\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.497, AUC-PR: 0.084\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.972, AUC-PR: 0.712\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.517, AUC-PR: 0.220\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.583, AUC-PR: 0.074\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.936, AUC-PR: 0.514\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.417, AUC-PR: 0.026\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.416, AUC-PR: 0.026\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.824, AUC-PR: 0.673\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.416, AUC-PR: 0.026\n",
      "\n",
      "Processing file: data/generated_data/dataset_13.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.478, AUC-PR: 0.014\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.575, AUC-PR: 0.020\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.773, AUC-PR: 0.094\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.567, AUC-PR: 0.095\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.594, AUC-PR: 0.028\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.437, AUC-PR: 0.011\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.853, AUC-PR: 0.080\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.853, AUC-PR: 0.080\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.832, AUC-PR: 0.074\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.853, AUC-PR: 0.080\n",
      "\n",
      "Processing file: data/generated_data/dataset_18.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.590, AUC-PR: 0.177\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.549, AUC-PR: 0.035\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.787, AUC-PR: 0.553\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.598, AUC-PR: 0.197\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.590, AUC-PR: 0.037\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.746, AUC-PR: 0.296\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.509, AUC-PR: 0.031\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.509, AUC-PR: 0.031\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.874, AUC-PR: 0.556\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.509, AUC-PR: 0.031\n",
      "\n",
      "Processing file: data/generated_data/dataset_9.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.282, AUC-PR: 0.000\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.312, AUC-PR: 0.000\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.858, AUC-PR: 0.002\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.251, AUC-PR: 0.000\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.519, AUC-PR: 0.000\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.711, AUC-PR: 0.001\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.745, AUC-PR: 0.001\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.745, AUC-PR: 0.001\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.871, AUC-PR: 0.002\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.745, AUC-PR: 0.001\n",
      "\n",
      "Processing file: data/generated_data/dataset_19.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.508, AUC-PR: 0.032\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.508, AUC-PR: 0.022\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.818, AUC-PR: 0.247\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.574, AUC-PR: 0.042\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.487, AUC-PR: 0.022\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.709, AUC-PR: 0.057\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.652, AUC-PR: 0.030\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.652, AUC-PR: 0.030\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.853, AUC-PR: 0.263\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.652, AUC-PR: 0.030\n",
      "\n",
      "Processing file: data/generated_data/dataset_8.test.csv in folder: generated_data\n",
      "\n",
      "Running CBLOF for generated_data...\n",
      "CBLOF - AUC-ROC: 0.400, AUC-PR: 0.008\n",
      "\n",
      "Running COF for generated_data...\n",
      "COF - AUC-ROC: 0.580, AUC-PR: 0.031\n",
      "\n",
      "Running kMeans for generated_data...\n",
      "kMeans - AUC-ROC: 0.852, AUC-PR: 0.791\n",
      "\n",
      "Running KNN for generated_data...\n",
      "KNN - AUC-ROC: 0.488, AUC-PR: 0.139\n",
      "\n",
      "Running LOF for generated_data...\n",
      "LOF - AUC-ROC: 0.660, AUC-PR: 0.064\n",
      "\n",
      "Running PS-SVM for generated_data...\n",
      "PS-SVM - AUC-ROC: 0.847, AUC-PR: 0.320\n",
      "\n",
      "Running STAMP for generated_data...\n",
      "STAMP - AUC-ROC: 0.231, AUC-PR: 0.009\n",
      "\n",
      "Running STOMP for generated_data...\n",
      "STOMP - AUC-ROC: 0.231, AUC-PR: 0.009\n",
      "\n",
      "Running Sub-LOF for generated_data...\n",
      "Sub-LOF - AUC-ROC: 0.862, AUC-PR: 0.772\n",
      "\n",
      "Running VALMOD for generated_data...\n",
      "VALMOD - AUC-ROC: 0.230, AUC-PR: 0.009\n",
      "\n",
      "Execution complete. Results and plots saved to './results'.\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "base_path = \"data/GutenTag\" # Change this to the base path of your dataset\n",
    "results_summary = []\n",
    "\n",
    "# Colors for methods (consistent across datasets)\n",
    "METHOD_COLORS = {\n",
    "    \"CBLOF\": \"blue\",\n",
    "    \"COF\": \"orange\",\n",
    "    \"kMeans\": \"red\",\n",
    "    \"KNN\": \"purple\",\n",
    "    \"LOF\": \"brown\",\n",
    "    \"PS-SVM\": \"pink\",\n",
    "    \"Sub-LOF\": \"yellow\",\n",
    "    \"VALMOD\": \"green\",\n",
    "}\n",
    "\n",
    "# Create directory for plots\n",
    "try:\n",
    "    os.makedirs(\"./results/plots\", exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directories: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Recursively find all test.csv files\n",
    "test_files = []\n",
    "try:\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\"test.csv\"):\n",
    "                test_files.append(os.path.join(root, file))\n",
    "except Exception as e:\n",
    "    print(f\"Error finding test files: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "if not test_files:\n",
    "    print(\"No test files found!\")\n",
    "    exit(1)\n",
    "\n",
    "# Process each test.csv file\n",
    "for test_file in test_files:\n",
    "    folder = os.path.basename(os.path.dirname(test_file))\n",
    "    print(f\"\\nProcessing file: {test_file} in folder: {folder}\")\n",
    "    \n",
    "    # Load test dataset with error handling\n",
    "    try:\n",
    "        data_test = safe_load_data(test_file)\n",
    "        if data_test is None:\n",
    "            print(f\"Skipping file {test_file} due to loading error\")\n",
    "            continue\n",
    "        \n",
    "        x_values = range(len(data_test))\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing data for {test_file}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize results for the file\n",
    "    file_results = []\n",
    "    anomaly_scores_dict = {}\n",
    "    \n",
    "    for algo_name in ALGORITHMS.keys():\n",
    "        print(f\"\\nRunning {algo_name} for {folder}...\")\n",
    "        \n",
    "        # Clear memory before each algorithm\n",
    "        gc.collect()\n",
    "        \n",
    "        try:\n",
    "            # Check memory usage before starting\n",
    "            check_memory_usage()\n",
    "            \n",
    "            # Set algorithm parameters\n",
    "            try:\n",
    "                custom_params = {\n",
    "                    \"CBLOF\": {\"n_clusters\": 50, \"random_state\": 42},\n",
    "                    \"COF\": {\"n_neighbors\": 50, \"random_state\": 42},\n",
    "                    \"kMeans\": {\"n_clusters\": 50, \"anomaly_window_size\": 100, \"random_state\": 42},\n",
    "                    \"KNN\": {\"n_neighbors\": 50, \"leaf_size\": 20, \"random_state\": 42},\n",
    "                    \"LOF\": {\"n_neighbors\": 50, \"leaf_size\": 20, \"random_state\": 42},\n",
    "                    \"PS-SVM\": {\"random_state\": 42},\n",
    "                    \"STAMP\": {\"window_size\": 100, \"verbose\": 0, \"random_state\": 42},\n",
    "                    \"STOMP\": {\"window_size\": 100, \"verbose\": 0, \"random_state\": 42},\n",
    "                    \"Sub-LOF\": {\"n_neighbors\": 50, \"leaf_size\": 20, \"random_state\": 42},\n",
    "                    \"VALMOD\": {\"verbose\": 0, \"random_state\": 42}\n",
    "                }.get(algo_name, {})\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting parameters for {algo_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if platform.system() != 'Windows':\n",
    "                # Unix implementation using signal\n",
    "                def timeout_handler(signum, frame):\n",
    "                    raise TimeoutError(f\"Operation timed out after 60 seconds for {algo_name}\")\n",
    "\n",
    "                # Set up signal handler\n",
    "                signal.signal(signal.SIGALRM, timeout_handler)\n",
    "                signal.alarm(60)\n",
    "\n",
    "                try:\n",
    "                    # Run algorithm\n",
    "                    scores = run_algorithm(algo_name, test_file, custom_parameters=custom_params)\n",
    "                    check_memory_usage()  # Check memory after algorithm run\n",
    "                    \n",
    "                    # Post-processing (if needed)\n",
    "                    if algo_name in \"STAMP\":\n",
    "                        scores = post_stamp(scores, custom_params)\n",
    "                    elif algo_name == \"STOMP\":\n",
    "                        scores = post_stomp(scores, custom_params)\n",
    "                    elif algo_name == \"Sub-LOF\":\n",
    "                        scores = post_sLOF(scores, custom_params)\n",
    "                    elif algo_name == \"VALMOD\":\n",
    "                        scores = post_valmod(scores, custom_params)\n",
    "                    \n",
    "                    check_memory_usage()  # Check memory after post-processing\n",
    "                \n",
    "                finally:\n",
    "                    signal.alarm(0)  # Disable the alarm\n",
    "\n",
    "            else:\n",
    "                # Windows implementation using threading\n",
    "                result = []\n",
    "                error = []\n",
    "\n",
    "                def worker():\n",
    "                    try:\n",
    "                        # Run algorithm\n",
    "                        scores = run_algorithm(algo_name, test_file, custom_parameters=custom_params)\n",
    "                        check_memory_usage()\n",
    "                        \n",
    "                        # Post-processing (if needed)\n",
    "                        if algo_name == \"STAMP\":\n",
    "                            scores = post_stamp(scores, custom_params)\n",
    "                        elif algo_name == \"STOMP\":\n",
    "                            scores = post_stomp(scores, custom_params)\n",
    "                        elif algo_name == \"Sub-LOF\":\n",
    "                            scores = post_sLOF(scores, custom_params)\n",
    "                        elif algo_name == \"VALMOD\":\n",
    "                            scores = post_valmod(scores, custom_params)\n",
    "                        \n",
    "                        check_memory_usage()\n",
    "                        result.append(scores)\n",
    "                    except Exception as e:\n",
    "                        error.append(e)\n",
    "                        traceback.print_exc()  # Print full traceback\n",
    "\n",
    "                thread = threading.Thread(target=worker)\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "                thread.join(60)  # 60 second timeout\n",
    "\n",
    "                if thread.is_alive():\n",
    "                    raise TimeoutError(f\"Operation timed out after 60 seconds for {algo_name}\")\n",
    "                if error:\n",
    "                    raise error[0]\n",
    "                scores = result[0]\n",
    "\n",
    "            # Evaluate algorithm\n",
    "            try:\n",
    "                auc_roc, auc_pr = evaluate_algorithm(scores, test_file)\n",
    "                print(f\"{algo_name} - AUC-ROC: {auc_roc:.3f}, AUC-PR: {auc_pr:.3f}\")\n",
    "                \n",
    "                # Store results\n",
    "                file_results.append({\"Algorithm\": algo_name, \"AUC-ROC\": auc_roc, \"AUC-PR\": auc_pr})\n",
    "                \n",
    "                # Normalize scores for plotting\n",
    "                min_val, max_val = np.min(scores), np.max(scores)\n",
    "                scores = np.zeros_like(scores) if min_val == max_val else (scores - min_val) / (max_val - min_val)\n",
    "                anomaly_scores_dict[algo_name] = scores\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in evaluation phase for {algo_name}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        except MemoryError as me:\n",
    "            print(f\"Memory error running {algo_name} for {folder}: {me}\")\n",
    "            gc.collect()  # Force garbage collection\n",
    "            continue\n",
    "        except TimeoutError as te:\n",
    "            print(f\"Timeout error: {te}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error running {algo_name} for {folder}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Plot results for this file\n",
    "    try:\n",
    "        if not anomaly_scores_dict:  # Skip plotting if no algorithms succeeded\n",
    "            print(f\"Skipping plots for {folder} as no algorithms completed successfully\")\n",
    "            continue\n",
    "            \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Subplot 1: Test time series\n",
    "        plt.subplot(2, 1, 1)\n",
    "        for col in data_test.iloc[:, 1:-1].columns:\n",
    "            plt.plot(x_values, data_test[col], label=f\"{col}\")\n",
    "        \n",
    "        anomaly_mask = data_test.iloc[:, -1] == 1\n",
    "        anomaly_regions = data_test[anomaly_mask].index\n",
    "        if not anomaly_regions.empty:\n",
    "            start = None\n",
    "            for i in range(len(anomaly_regions)):\n",
    "                if start is None:\n",
    "                    start = anomaly_regions[i]\n",
    "                if i == len(anomaly_regions) - 1 or anomaly_regions[i + 1] != anomaly_regions[i] + 1:\n",
    "                    end = anomaly_regions[i]\n",
    "                    plt.axvspan(start, end, color=\"red\", alpha=0.3, \n",
    "                              label=\"Anomaly\" if start == anomaly_regions[0] else \"\")\n",
    "                    start = None\n",
    "\n",
    "        plt.title(f\"Test Time Series - {folder}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Subplot 2: Anomaly scores\n",
    "        plt.subplot(2, 1, 2)\n",
    "        for algo_name, scores in anomaly_scores_dict.items():\n",
    "            plt.plot(x_values, scores, label=f\"{algo_name}\", \n",
    "                    color=METHOD_COLORS.get(algo_name, \"gray\"))\n",
    "        plt.title(\"Anomaly Scores\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save plot\n",
    "        try:\n",
    "            plot_filename = os.path.join(\"./results/plots\", \n",
    "                                       f\"{folder}_{os.path.basename(test_file)}_scores.png\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot for {folder}: {e}\")\n",
    "        finally:\n",
    "            plt.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating plots for {folder}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    \n",
    "    # Append results for this file\n",
    "    if file_results:  # Only append if we have results\n",
    "        results_summary.append({\"File\": test_file, \"Results\": file_results})\n",
    "\n",
    "# Compute and save average AUC scores\n",
    "try:\n",
    "    if results_summary:  # Only process if we have results\n",
    "        average_auc_scores = {}\n",
    "        for result in results_summary:\n",
    "            for algo_result in result[\"Results\"]:\n",
    "                algo_name = algo_result[\"Algorithm\"]\n",
    "                auc_score = algo_result[\"AUC-ROC\"]\n",
    "                if algo_name not in average_auc_scores:\n",
    "                    average_auc_scores[algo_name] = []\n",
    "                average_auc_scores[algo_name].append(auc_score)\n",
    "\n",
    "        # Compute averages\n",
    "        average_auc_scores = {algo: np.mean(scores) \n",
    "                            for algo, scores in average_auc_scores.items()}\n",
    "\n",
    "        # Save summary results\n",
    "        try:\n",
    "            results_df = pd.DataFrame(results_summary)\n",
    "            results_df.to_csv(\"./results/summary_results.csv\", index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving summary results: {e}\")\n",
    "\n",
    "        # Plot average AUC scores\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(average_auc_scores.keys(), average_auc_scores.values(),\n",
    "                   color=[METHOD_COLORS.get(algo, \"gray\") \n",
    "                         for algo in average_auc_scores.keys()])\n",
    "            plt.title(\"Average AUC-ROC Scores by Algorithm\")\n",
    "            plt.xlabel(\"Algorithm\")\n",
    "            plt.ylabel(\"Average AUC-ROC\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"./results/plots/average_auc_scores.png\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating average AUC score plot: {e}\")\n",
    "    else:\n",
    "        print(\"No results were generated to summarize!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in final summary and plotting: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Notify completion\n",
    "print(\"\\nExecution complete. Results and plots saved to './results'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
