{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GutenTAG data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows you to generate new, synthetic datasets. The degrees of freedom are endless. You can choose the base oscillation, the number and type of anomalies, where they will be present in your time series, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement gutenTAG (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for gutenTAG\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gutenTAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenTAG import GutenTAG, TrainingType\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the folder to save the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"data/generated_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "infos_folder = \"data/generated_data/info_generated_data\"\n",
    "os.makedirs(infos_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 20\n",
    "length = 10000\n",
    "base_oscillations = [{\"kind\": \"cylinder-bell-funnel\"}]\n",
    "anomalies_positions = [\"beginning\", \"middle\", \"end\"]\n",
    "\n",
    "min_anomalies_per_dataset = 1\n",
    "max_anomalies_per_dataset = 5\n",
    "\n",
    "# Dataset Generation Stats for posterior analysis\n",
    "stats_anomaly_position = {\"beginning\": 0, \"middle\": 0, \"end\": 0}\n",
    "stats_anomaly_kind = {\"amplitude\": 0, \"pattern\": 0, \"platform\": 0, \"trend\": 0}\n",
    "\n",
    "# Seeds for reproducibility\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(0, int(50*num_datasets)) for _ in range(num_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n",
      "Initializing addons: 0it [00:00, ?it/s]\n",
      "Generating datasets:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finalizing addons: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_datasets):\n",
    "    random.seed(random_seeds[i])\n",
    "    name = \"dataset_\" + str(i)\n",
    "    anomalies = []\n",
    "    for _ in range(random.randint(min_anomalies_per_dataset, max_anomalies_per_dataset)):\n",
    "        anomalies_kinds = [{\"kind\": \"amplitude\", \"amplitude_factor\": random.uniform(1.5, 5.0)},\n",
    "                           {\"kind\": \"pattern\", \"cbf_pattern_factor\": random.uniform(5.0, 20.0)},\n",
    "                           {\"kind\": \"platform\", \"value\": random.uniform(0.0, 5.0)},\n",
    "                           {\"kind\": \"trend\", \"oscillation\": {\"kind\": \"cylinder-bell-funnel\"}}]\n",
    "        anomalies.append({\"position\": anomalies_positions[random.randint(0, 2)], \"length\": int(10*random.randint(1, 20)/2), \"kinds\": [anomalies_kinds[random.randint(0, len(anomalies_kinds)-1)]]})\n",
    "\n",
    "    config = {\n",
    "        \"timeseries\": [\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"length\": length,\n",
    "                \"base-oscillations\": base_oscillations,\n",
    "                \"anomalies\": anomalies\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    gutentag = GutenTAG(seed=random.randint(0, 100))\n",
    "    gutentag.load_config_dict(config)\n",
    "\n",
    "    # call generate() to create the datasets (in-memory)\n",
    "    datasets = gutentag.generate(return_timeseries=True)\n",
    "\n",
    "    # we only defined a single test time series\n",
    "    assert len(datasets) == 1\n",
    "    d = datasets[0]\n",
    "    assert d.name == name\n",
    "    assert d.training_type == TrainingType.TEST\n",
    "\n",
    "    # the data points are stored at\n",
    "    df = d.timeseries\n",
    "    df.iloc[:, 1:-1]\n",
    "\n",
    "    # Add a 'timestamp' column as the first column\n",
    "    df.insert(0, 'timestamp', range(len(df)))\n",
    "\n",
    "    # Data stats\n",
    "    for anomaly in config['timeseries'][0]['anomalies']:\n",
    "        stats_anomaly_position[anomaly['position']] += 1\n",
    "        stats_anomaly_kind[anomaly['kinds'][0]['kind']] += 1\n",
    "\n",
    "    # Save dataset info to a TXT file\n",
    "    file_path = os.path.join(infos_folder, f\"{name}.txt\")\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(config[\"timeseries\"][0], file, indent=4)\n",
    "\n",
    "    # Save the dataset to a CSV file\n",
    "    output_file = os.path.join(output_folder, f\"{name}.test.csv\")\n",
    "    df.to_csv(output_file, index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beginning': 17, 'middle': 17, 'end': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_anomaly_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amplitude': 18, 'pattern': 14, 'platform': 9, 'trend': 13}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_anomaly_kind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
